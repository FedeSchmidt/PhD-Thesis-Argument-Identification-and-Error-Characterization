{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f04f2c-a679-459c-a251-4c8521d8861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "current_path = Path().resolve().parent\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab0885bc-263a-4461-bdc5-a6b095b1f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "    instances = []\n",
    "    try:\n",
    "        with open(file_path, encoding='utf-8') as nf:\n",
    "            lines = nf.readlines()\n",
    "            tokens, labels, predictions = [], [], []\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    tk, lb, pr = line.split()\n",
    "                    tokens.append(tk)\n",
    "                    labels.append(lb)\n",
    "                    predictions.append(pr)\n",
    "                else:\n",
    "                    instances.append((tokens, labels, predictions))\n",
    "                    tokens, labels, predictions = [], [], []\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except ValueError:\n",
    "        print(f\"Invalid file format: {file_path}\")\n",
    "\n",
    "    return instances\n",
    "\n",
    "def get_arguments_indices(sequence):\n",
    "    indices = []\n",
    "    start_index = None\n",
    "    for i, label in enumerate(sequence):\n",
    "        if label == '1':\n",
    "            \n",
    "            if start_index is None:\n",
    "                start_index = i\n",
    "            else:\n",
    "                indices.append((start_index, i))\n",
    "                start_index = i\n",
    "        \n",
    "        elif (label == '0') and (start_index is not None):\n",
    "            indices.append((start_index, i))\n",
    "            start_index = None\n",
    "\n",
    "    if start_index is not None:\n",
    "        indices.append((start_index, len(sequence)))\n",
    "\n",
    "    return indices\n",
    "\n",
    "def compute_r_matrix(gold_indices, predicted_indices):\n",
    "\n",
    "    def get_R(gold_argument, predicted_argument):\n",
    "        (gold_start, gold_end) = gold_argument\n",
    "        (pred_start, pred_end) = predicted_argument\n",
    "\n",
    "        intersection_start = max(gold_start, pred_start)\n",
    "        intersection_end = min(gold_end, pred_end)\n",
    "\n",
    "        len_intersection_interval = (intersection_end - intersection_start) if intersection_start <= intersection_end else 0\n",
    "        len_longer_span = max(gold_end - gold_start, pred_end - pred_start)\n",
    "        return round((len_intersection_interval / len_longer_span), 3)\n",
    "    \n",
    "    R_matrix = np.zeros((len(gold_indices), len(predicted_indices)), dtype=float)\n",
    "    \n",
    "    for i, gold_argument in enumerate(gold_indices):\n",
    "        for j, predicted_argument in enumerate(predicted_indices):\n",
    "            R_matrix[i][j] = get_R(gold_argument, predicted_argument)\n",
    "    \n",
    "    return R_matrix\n",
    "\n",
    "def categorize(matrix, tau = 0.7, omega = 0.3):\n",
    "\n",
    "    def is_split(matrix, column):\n",
    "        gold_row_index = np.where(column > 0)[0]\n",
    "        gold_row = matrix[gold_row_index, :]\n",
    "        positive_values = gold_row[gold_row > 0].tolist()\n",
    "        if len(positive_values) > 1:\n",
    "            sum_values = sum(positive_values)\n",
    "            greater_than_omega = [x >= omega for x in positive_values]\n",
    "            if (sum_values >= tau) and (all(greater_than_omega)):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    gold_arguments_names = [f'G{i}' for i in range(matrix.shape[0])]\n",
    "    predicted_arguments_names = [f'P{i}' for i in range(matrix.shape[1])]\n",
    "\n",
    "    categorization = { 'PM': 0, 'DISP': 0, 'SP': 0, 'MG': 0, 'MU': 0, 'UNR': 0 }\n",
    "\n",
    "    for i, pred_arg in enumerate(predicted_arguments_names):\n",
    "        column = matrix[:, i]\n",
    "        positive_values = column[column > 0].tolist()\n",
    "        # print(positive_values)\n",
    "        if len(positive_values) == 0:\n",
    "            categorization[pred_arg] = 'MU'\n",
    "        elif len(positive_values) == 1:\n",
    "            if positive_values[0] == 1:\n",
    "                categorization[pred_arg] = 'PM'\n",
    "            else:\n",
    "                if is_split(matrix, column):\n",
    "                    categorization[pred_arg] = 'SP'\n",
    "                else:\n",
    "                    categorization[pred_arg] = 'DISP'\n",
    "\n",
    "        elif len(positive_values) > 1:\n",
    "            sum_values = sum(positive_values)\n",
    "            greater_than_omega = [x >= omega for x in positive_values]\n",
    "            \n",
    "            if (sum_values >= tau) and (all(greater_than_omega)):\n",
    "                categorization[pred_arg] = 'MG'\n",
    "            else:\n",
    "                categorization[pred_arg] = 'DISP'\n",
    "\n",
    "    for i, gold_arg in enumerate(gold_arguments_names):\n",
    "        row = matrix[i, :]\n",
    "        positive_values = row[row > 0].tolist()\n",
    "        if len(positive_values) == 0:\n",
    "            categorization[gold_arg] = 'UNR'\n",
    "\n",
    "    return categorization\n",
    "\n",
    "def get_best_run_number(row):\n",
    "    columns = [f'run{i}' for i in range(10)]\n",
    "    values = row[columns].values\n",
    "    return np.argmax(values)\n",
    "\n",
    "def r_average(counter, total_gold_argument_units):\n",
    "    # print(counter, total_gold_argument_units)\n",
    "    suma_r_values = sum(x[1] for x in counter)\n",
    "    return round(suma_r_values / len(counter), 2), round(suma_r_values / total_gold_argument_units, 2), len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9a4fc-198d-47e3-a772-57aa030fc8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_results = pd.read_csv(str(current_path / 'data.csv'))\n",
    "f1_results['best_run'] = f1_results.apply(lambda row: get_best_run_number(row), axis = 1)\n",
    "\n",
    "print(f1_results.shape)\n",
    "f1_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f4907b1-aa6d-42a4-93bc-85490b0fb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_btas(lista):\n",
    "    count = collections.Counter()\n",
    "    for x in lista:\n",
    "        count.update(x)\n",
    "\n",
    "    return count['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dadcb87-2e5a-44ca-af85-19b6d05ed5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ['pe', 'we', 'abam', 'mix1']\n",
    "test_set = ['pe', 'we', 'abam']\n",
    "models = ['bert', 'bert_crf', 'distilbert', 'distilbert_crf', 'distilbert_bilstmcrf', 'bert_bilstmcrf']\n",
    "\n",
    "info_df_results = []\n",
    "\n",
    "for test in test_set:\n",
    "    for elem in train_set:\n",
    "        for model in models:\n",
    "            best_run = f1_results.loc[(f1_results['train'] == elem) & (f1_results['test'] == test) & (f1_results['model'] == model)].best_run.values[0]\n",
    "        \n",
    "            total_counter_categorization = collections.Counter({'PM':0, 'DISP': 0, 'SP': 0, 'MG': 0, 'MU': 0, 'UNR': 0})\n",
    "\n",
    "            folder_dir = f\"{elem}_{model}\"\n",
    "            model_name = \"-\".join(model.split(\"_\"))\n",
    "            file_name = f\"results-{elem}-{test}-{model_name}-{best_run}.txt\"\n",
    "            file_path = (current_path / 'results' / 'BIO' / folder_dir / file_name)\n",
    "            \n",
    "            total_gold_argument_units, total_pred_argument_units = 0, 0\n",
    "\n",
    "            instances = parse_file(file_path)\n",
    "\n",
    "            btags_gold = get_number_btas([x[1] for x in instances])\n",
    "            btags_pred = get_number_btas([x[2] for x in instances])\n",
    "\n",
    "            for (tokens, labels, predictions) in instances:\n",
    "                arg_component_indices = get_arguments_indices(labels)\n",
    "                arg_predicted_indices = get_arguments_indices(predictions)\n",
    "\n",
    "                total_gold_argument_units += len(arg_component_indices)\n",
    "                total_pred_argument_units += len(arg_predicted_indices)\n",
    "\n",
    "                if (len(arg_component_indices) > 0) or (len(arg_predicted_indices) > 0):\n",
    "\n",
    "                    R_matrix = compute_r_matrix(arg_component_indices, arg_predicted_indices)\n",
    "\n",
    "                    categorization = categorize(R_matrix, 0.7, 0.35)\n",
    "\n",
    "                    total_counter_categorization.update(collections.Counter(categorization.values()))\n",
    "\n",
    "\n",
    "            row_df_results = [elem, test, model, total_gold_argument_units, total_pred_argument_units] + [total_counter_categorization[x] for x in ['PM', 'DISP', 'SP', 'MG', 'MU', 'UNR']]\n",
    "\n",
    "            info_df_results.append(row_df_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74712511-8cde-4443-9f5a-45d60d0cab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_results_df = pd.DataFrame(info_df_results, \n",
    "             columns = ['train', 'test', 'model', 'gold_arguments', 'predicted_arguments', 'PM', 'DISP', 'SP', 'MG', 'MU', 'UNR'])\n",
    "\n",
    "errors_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
