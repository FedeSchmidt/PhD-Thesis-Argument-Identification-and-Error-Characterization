{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2bef3-5d51-4f1b-b807-d7dc5051356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "current_path = Path().resolve().parent\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5431d2f9-6af6-43a3-92ec-551631e1b4e7",
   "metadata": {},
   "source": [
    "# Transformer-based and LSTM-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acc4a41-9f16-470f-9996-fd6dcdb59fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = ['pe', 'we', 'abam', 'mix1']\n",
    "test_sets = ['pe', 'we', 'abam', 'mix1']\n",
    "\n",
    "models = ['bert', 'bert_crf', 'distilbert', 'distilbert_crf', 'glove_bilstmcrf', 'distilbert_bilstmcrf', 'bert_bilstmcrf']\n",
    "\n",
    "df_info = []\n",
    "\n",
    "def parse_file(file_path):\n",
    "    tokens, labels, predictions = [], [], []\n",
    "    try:\n",
    "        with open(file_path, encoding='utf-8') as nf:\n",
    "            lines = nf.readlines()\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    tk, lb, pr = line.split()\n",
    "                    tokens.append(tk)\n",
    "                    labels.append(lb)\n",
    "                    predictions.append(pr)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except ValueError:\n",
    "        print(f\"Invalid file format: {file_path}\")\n",
    "\n",
    "    return tokens, labels, predictions\n",
    "\n",
    "for train in train_sets:\n",
    "    for test in test_sets:\n",
    "        \n",
    "        for m in models:\n",
    "            folder_dir = f\"{train}_{m}\"\n",
    "            \n",
    "            row = [train, test, m]\n",
    "\n",
    "            model_name = \"-\".join(m.split(\"_\"))\n",
    "            for i in range(10):\n",
    "                file_name = f\"results-{train}-{test}-{model_name}-{i}.txt\"\n",
    "                file_path = (current_path / 'results' / 'BIO' / folder_dir / file_name)\n",
    "                tokens, labels, predictions = parse_file(file_path)\n",
    "                # print(file_name)\n",
    "                fmacro = f1_score(labels, predictions, average = 'macro')\n",
    "                row.append(fmacro)\n",
    "            \n",
    "            df_info.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e1e08-f2d7-48bd-9256-14f1c48e3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = pd.DataFrame(df_info, columns = ['train', 'test', 'model'] + [f'run{i}' for i in range(10)])\n",
    "results_dataframe['average'] = results_dataframe.loc[:, 'run0':'run9'].mean(axis=1)\n",
    "results_dataframe['std_deviation'] = results_dataframe.loc[:, 'run0':'run9'].std(axis=1)\n",
    "results_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4951c79-7b74-4f5a-8cc6-7fd2245cc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe.to_csv(str(current_path) + \"/data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd99e4-7d96-4c31-846b-183a97f4540e",
   "metadata": {},
   "source": [
    "# MTL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a02944c0-eac6-463c-80dc-f54f9102393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "    tokens, labels, predictions = [], [], []\n",
    "    try:\n",
    "        with open(file_path, encoding='utf-8') as nf:\n",
    "            lines = nf.readlines()\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    tk, lb, pr = line.split()\n",
    "                    tokens.append(tk)\n",
    "                    labels.append(lb)\n",
    "                    predictions.append(pr)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except ValueError:\n",
    "        print(f\"Invalid file format: {file_path}\")\n",
    "\n",
    "    return tokens, labels, predictions\n",
    "\n",
    "test_sets = ['pe', 'we', 'abam']\n",
    "folder_cues = ['equal', 'dwa', 'dwaT3', 'dwaT5']\n",
    "\n",
    "df_info = []\n",
    "\n",
    "for folder_cue in folder_cues:\n",
    "    folder_dir = f\"mtl_{folder_cue}\"\n",
    "    weighting = 'dwa' if folder_cue.startswith('dwa') else 'equal'\n",
    "    for test in test_sets:\n",
    "        for i in range(3):\n",
    "            row = [test, weighting, folder_cue, i]\n",
    "            for j in range(10):\n",
    "                file_name = f\"results-mtl-{weighting}-{test}-bert-{j}-CRF{i}.txt\"\n",
    "                file_path = (current_path / 'results' / 'BIO' / folder_dir / file_name)\n",
    "                tokens, labels, predictions = parse_file(file_path)\n",
    "                fmacro = f1_score(labels, predictions, average = 'macro')\n",
    "                row.append(fmacro)\n",
    "            df_info.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d6f09-51f7-4efc-b989-c406e73c1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = pd.DataFrame(df_info, columns = ['test', 'weighting', 'weighting_cue', 'crf'] + [f'run{i}' for i in range(10)])\n",
    "results_dataframe['average'] = results_dataframe.loc[:, 'run0':'run9'].mean(axis=1)\n",
    "results_dataframe['std_deviation'] = results_dataframe.loc[:, 'run0':'run9'].std(axis=1)\n",
    "results_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271f5634-df35-4061-922e-870eb941e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe.to_csv(str(current_path) + \"/data_mtl.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
